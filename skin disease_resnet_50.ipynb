{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check presence of GPU\n",
    "is_gpu_avalaible = torch.cuda.is_available()\n",
    "print(is_gpu_avalaible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dataset/eczema/\"\n",
    "\n",
    "train_dir = os.path.join(data, \"train/\")\n",
    "test_dir = os.path.join(data, \"test/\")\n",
    "val_dir = os.path.join(data, \"val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Atopic dermatitis\", \"Contact dermatitis\", \"Dyshidrotic eczema\",\"Hand eczema\",\"Neurodermatitis\",\"Nummular eczema\",\"Stasis dermatitis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = data\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transformer = transforms.Compose([transforms.RandomResizedCrop(224), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = datasets.ImageFolder(train_dir, transform=data_transformer)\n",
    "# val_data = datasets.ImageFolder(val_dir, transform=data_transformer)\n",
    "# # test_data = datasets.ImageFolder(test_dir, transform=data_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training image number is {len(train_data)}\")\n",
    "# print(f\"Test image number is {len(test_data)}\")\n",
    "# print(f\"Validation image number is {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image into torch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Const\n",
    "# batch_size = 32train_loader = DataLoader(train_data, batch_size=batch_size,  num_workers=num_workers, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_data, batch_size=batch_size,  num_workers=num_workers, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, lables = iter(train_loader).next()\n",
    "# img = img.numpy()\n",
    "# # plt.imshow(img)\n",
    "\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# for idx in np.arange(20):\n",
    "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "#     plt.imshow(np.transpose(img[idx], (1, 2, 0)))\n",
    "#     ax.set_title(classes[lables[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model slection\n",
    "resnet_50 = models.resnet50(pretrained=True)\n",
    "# print(resnet_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(resnet_50.fc.in_features)\n",
    "print(resnet_50.fc.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the feature layers\n",
    "for weights in resnet_50.parameters():\n",
    "    weights.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new output size is: 7\n"
     ]
    }
   ],
   "source": [
    "# updating the last fully connected layer\n",
    "num_inputs = resnet_50.fc.in_features\n",
    "\n",
    "# add linear layers with new number of classes\n",
    "resnet_50.fc = nn.Linear(num_inputs, len(classes))\n",
    "\n",
    "# add the model to gpu\n",
    "resnet_50 = resnet_50.to(device)\n",
    "\n",
    "\n",
    "## Verify that the number output changeto the len of the class\n",
    "print(f\"The new output size is: {resnet_50.fc.out_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and Optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "optimzer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimzer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.9301 Acc: 0.1887\n",
      "val Loss: 1.8879 Acc: 0.2590\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.8677 Acc: 0.2465\n",
      "val Loss: 1.8159 Acc: 0.2852\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.8311 Acc: 0.2731\n",
      "val Loss: 1.7314 Acc: 0.3279\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.8076 Acc: 0.2893\n",
      "val Loss: 1.6948 Acc: 0.3574\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.8030 Acc: 0.2934\n",
      "val Loss: 1.6580 Acc: 0.3738\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.7879 Acc: 0.2920\n",
      "val Loss: 1.6036 Acc: 0.3934\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.7728 Acc: 0.3096\n",
      "val Loss: 1.6261 Acc: 0.3803\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.7429 Acc: 0.3255\n",
      "val Loss: 1.5874 Acc: 0.4066\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.7484 Acc: 0.3298\n",
      "val Loss: 1.5973 Acc: 0.3934\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.7479 Acc: 0.3329\n",
      "val Loss: 1.5995 Acc: 0.3902\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.7479 Acc: 0.3325\n",
      "val Loss: 1.5880 Acc: 0.4131\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.7536 Acc: 0.3120\n",
      "val Loss: 1.5992 Acc: 0.3705\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.7450 Acc: 0.3359\n",
      "val Loss: 1.5969 Acc: 0.3869\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.7466 Acc: 0.3285\n",
      "val Loss: 1.5811 Acc: 0.3836\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.7390 Acc: 0.3241\n",
      "val Loss: 1.5788 Acc: 0.4000\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.7356 Acc: 0.3298\n",
      "val Loss: 1.5744 Acc: 0.4098\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.7300 Acc: 0.3369\n",
      "val Loss: 1.5954 Acc: 0.3803\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.7419 Acc: 0.3352\n",
      "val Loss: 1.5884 Acc: 0.4098\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.7339 Acc: 0.3288\n",
      "val Loss: 1.5752 Acc: 0.4066\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.7358 Acc: 0.3234\n",
      "val Loss: 1.5923 Acc: 0.3902\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.7295 Acc: 0.3420\n",
      "val Loss: 1.5923 Acc: 0.3803\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.7451 Acc: 0.3285\n",
      "val Loss: 1.5887 Acc: 0.4000\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.7274 Acc: 0.3450\n",
      "val Loss: 1.6000 Acc: 0.4033\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.7468 Acc: 0.3268\n",
      "val Loss: 1.5759 Acc: 0.4066\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 1.7322 Acc: 0.3423\n",
      "val Loss: 1.6051 Acc: 0.3803\n",
      "\n",
      "Training complete in 13m 18s\n",
      "Best val Acc: 0.413115\n"
     ]
    }
   ],
   "source": [
    "resnet_50 = train_model(resnet_50, criterion, optimzer, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
