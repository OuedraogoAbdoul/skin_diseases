{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check presence of GPU\n",
    "is_gpu_avalaible = torch.cuda.is_available()\n",
    "print(is_gpu_avalaible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dataset/eczema/\"\n",
    "\n",
    "train_dir = os.path.join(data, \"train/\")\n",
    "test_dir = os.path.join(data, \"test/\")\n",
    "val_dir = os.path.join(data, \"val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Atopic dermatitis\", \"Contact dermatitis\", \"Dyshidrotic eczema\",\"Hand eczema\",\"Neurodermatitis\",\"Nummular eczema\",\"Stasis dermatitis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = data\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transformer = transforms.Compose([transforms.RandomResizedCrop(224), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = datasets.ImageFolder(train_dir, transform=data_transformer)\n",
    "# val_data = datasets.ImageFolder(val_dir, transform=data_transformer)\n",
    "# # test_data = datasets.ImageFolder(test_dir, transform=data_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training image number is {len(train_data)}\")\n",
    "# print(f\"Test image number is {len(test_data)}\")\n",
    "# print(f\"Validation image number is {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image into torch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Const\n",
    "# batch_size = 32train_loader = DataLoader(train_data, batch_size=batch_size,  num_workers=num_workers, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_data, batch_size=batch_size,  num_workers=num_workers, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, lables = iter(train_loader).next()\n",
    "# img = img.numpy()\n",
    "# # plt.imshow(img)\n",
    "\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# for idx in np.arange(20):\n",
    "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "#     plt.imshow(np.transpose(img[idx], (1, 2, 0)))\n",
    "#     ax.set_title(classes[lables[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\personal/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6ccb81a9d44e9a93dc22a8ecaa4f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model slection\n",
    "resnet_18 = models.resnet18(pretrained=True)\n",
    "# print(resnet_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(resnet_18.fc.in_features)\n",
    "print(resnet_18.fc.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the feature layers\n",
    "for weights in resnet_18.parameters():\n",
    "    weights.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new output size is: 7\n"
     ]
    }
   ],
   "source": [
    "# updating the last fully connected layer\n",
    "num_inputs = resnet_18.fc.in_features\n",
    "\n",
    "# add linear layers with new number of classes\n",
    "resnet_18.fc = nn.Linear(num_inputs, len(classes))\n",
    "\n",
    "# add the model to gpu\n",
    "resnet_18 = resnet_18.to(device)\n",
    "\n",
    "\n",
    "## Verify that the number output changeto the len of the class\n",
    "print(f\"The new output size is: {resnet_18.fc.out_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and Optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "optimzer = optim.SGD(resnet_18.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimzer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.1060 Acc: 0.2272\n",
      "val Loss: 2.0813 Acc: 0.2754\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.0595 Acc: 0.2529\n",
      "val Loss: 1.9750 Acc: 0.3410\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.0377 Acc: 0.2522\n",
      "val Loss: 1.9919 Acc: 0.3902\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.0100 Acc: 0.2660\n",
      "val Loss: 1.9306 Acc: 0.3148\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.9854 Acc: 0.2853\n",
      "val Loss: 1.8624 Acc: 0.3180\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 2.0245 Acc: 0.2616\n",
      "val Loss: 1.7770 Acc: 0.3574\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 2.0169 Acc: 0.2643\n",
      "val Loss: 2.1903 Acc: 0.3836\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.7679 Acc: 0.3231\n",
      "val Loss: 1.6844 Acc: 0.4066\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.7528 Acc: 0.3278\n",
      "val Loss: 1.6613 Acc: 0.4098\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.7363 Acc: 0.3359\n",
      "val Loss: 1.6397 Acc: 0.4098\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.7393 Acc: 0.3275\n",
      "val Loss: 1.6318 Acc: 0.4230\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.7286 Acc: 0.3437\n",
      "val Loss: 1.6248 Acc: 0.4098\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.7221 Acc: 0.3484\n",
      "val Loss: 1.6134 Acc: 0.4623\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.7416 Acc: 0.3265\n",
      "val Loss: 1.6355 Acc: 0.4098\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.7116 Acc: 0.3457\n",
      "val Loss: 1.6540 Acc: 0.3967\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.6804 Acc: 0.3535\n",
      "val Loss: 1.6165 Acc: 0.4459\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.7055 Acc: 0.3410\n",
      "val Loss: 1.6200 Acc: 0.4230\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.6903 Acc: 0.3504\n",
      "val Loss: 1.5979 Acc: 0.4426\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.6952 Acc: 0.3589\n",
      "val Loss: 1.6295 Acc: 0.4230\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.6919 Acc: 0.3545\n",
      "val Loss: 1.6056 Acc: 0.4230\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.6749 Acc: 0.3717\n",
      "val Loss: 1.6171 Acc: 0.4525\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.7064 Acc: 0.3488\n",
      "val Loss: 1.6407 Acc: 0.4295\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.7023 Acc: 0.3433\n",
      "val Loss: 1.6348 Acc: 0.4131\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.7235 Acc: 0.3339\n"
     ]
    }
   ],
   "source": [
    "resnet_18 = train_model(resnet_18, criterion, optimzer, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
